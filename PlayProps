import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.config.SslConfigs;
import org.apache.kafka.common.errors.TimeoutException;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Profile;
import org.springframework.integration.annotation.IntegrationComponentScan;
import org.springframework.integration.channel.MessageChannels;
import org.springframework.integration.config.EnableIntegration;
import org.springframework.integration.dsl.IntegrationFlow;
import org.springframework.integration.dsl.IntegrationFlows;
import org.springframework.integration.handler.LoggingHandler;
import org.springframework.integration.kafka.outbound.KafkaProducerMessageHandler;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;
import org.springframework.kafka.support.serializer.JsonSerializer;
import org.springframework.messaging.Message;
import org.springframework.messaging.MessageChannel;
import org.springframework.expression.common.LiteralExpression;
import org.springframework.util.StringUtils;

import java.util.HashMap;
import java.util.Map;

/**
 * Outbound flow -> producerChannel -> Kafka with:
 * - Async sends for high throughput
 * - sendFailureChannel for error handling
 * - Producer reset on TimeoutException/NetworkException
 * - Re-queue failed messages to producerChannel
 */
@Slf4j
@Configuration
@EnableIntegration
@IntegrationComponentScan
@RequiredArgsConstructor
@Profile("kafka")
public class OutboundFlowKafkaConfig {

    private static final String APP_NAME = "solace-otel-collector";

    private final KafkaConfig kafkaConfig;

    // *** NEW: Hold reference for reset capability ***
    private DefaultKafkaProducerFactory<String, SolaceSyslogEvent> producerFactory;

    /**
     * Main outbound flow:
     * producerChannel -> kafkaMessageHandler (async - errors go to producerErrorChannel)
     */
    @Bean
    public IntegrationFlow kafkaIntegrationFlow(
            @Qualifier("producerChannel") MessageChannel producerChannel,
            KafkaProducerMessageHandler<String, SolaceSyslogEvent> kafkaMessageHandler
    ) {
        return IntegrationFlows.from(producerChannel)
                .handle(kafkaMessageHandler)
                .get();
    }

    /**
     * Error flow for async send failures
     * *** MODIFIED: Reset producer and re-queue on timeout errors ***
     */
    @Bean
    public IntegrationFlow producerErrorHandlingFlow(
            @Qualifier("producerErrorChannel") MessageChannel errorChannel,
            @Qualifier("producerChannel") MessageChannel producerChannel
    ) {
        return IntegrationFlows.from(errorChannel)
                .handle(m -> {
                    Throwable cause = extractCause(m.getPayload());
                    log.error("Async Kafka send failed: {}", cause.getMessage());
                    
                    if (shouldResetProducer(cause)) {
                        resetProducer();
                        
                        // Re-queue the original message
                        Message<?> failedMessage = extractFailedMessage(m.getPayload());
                        if (failedMessage != null) {
                            log.warn("Re-queuing message after producer reset");
                            producerChannel.send(failedMessage);
                        }
                    }
                })
                .get();
    }
    
    // Extract cause from ErrorMessage
    private Throwable extractCause(Object payload) {
        if (payload instanceof org.springframework.kafka.support.KafkaSendFailureException kfe) {
            return kfe.getCause() != null ? kfe.getCause() : kfe;
        }
        if (payload instanceof Throwable t) {
            return t;
        }
        return new RuntimeException("Unknown error: " + payload);
    }
    
    // Extract original message from ErrorMessage
    private Message<?> extractFailedMessage(Object payload) {
        if (payload instanceof org.springframework.kafka.support.KafkaSendFailureException kfe) {
            return kfe.getFailedMessage();
        }
        return null;
    }

    /**
     * DLQ flow - messages that exhausted SI retry land here.
     */
    @Bean
    public IntegrationFlow kafkaDlqFlow(@Qualifier("kafkaDlqChannel") MessageChannel dlqChannel) {
        return IntegrationFlows.from(dlqChannel)
                .log(LoggingHandler.Level.ERROR, "KafkaDLQ",
                        m -> "Message sent to DLQ after retries: " + m.getPayload())
                .get();
    }

    @Bean
    public MessageChannel producerErrorChannel() {
        return MessageChannels.queue("producerErrorChannel", 100).getObject();
    }

    @Bean
    public MessageChannel kafkaDlqChannel() {
        return MessageChannels.queue("kafkaDlqChannel", 1000).getObject();
    }

    // *** NEW: Check if error warrants producer reset ***
    private boolean shouldResetProducer(Throwable throwable) {
        if (throwable == null) return false;
        
        Throwable cause = throwable;
        while (cause != null) {
            String name = cause.getClass().getSimpleName();
            if (cause instanceof TimeoutException ||
                name.contains("NetworkException") ||
                name.contains("DisconnectException") ||
                name.contains("TimeoutException")) {
                return true;
            }
            cause = cause.getCause();
        }
        return false;
    }

    // *** NEW: Reset the producer to force new connection ***
    private synchronized void resetProducer() {
        if (producerFactory != null) {
            log.warn("Resetting Kafka producer due to connection/timeout error");
            try {
                producerFactory.reset();
                log.info("Kafka producer reset successfully - new connection will be established");
            } catch (Exception e) {
                log.error("Failed to reset Kafka producer", e);
            }
        }
    }

    /**
     * Kafka handler - async for high throughput
     */
    @Bean
    public KafkaProducerMessageHandler<String, SolaceSyslogEvent> kafkaMessageHandler() {
        KafkaProducerMessageHandler<String, SolaceSyslogEvent> handler =
                new KafkaProducerMessageHandler<>(kafkaTemplate());
        handler.setTopicExpression(new LiteralExpression(kafkaConfig.getTopic()));
        handler.setMessageKeyExpression(new LiteralExpression(APP_NAME));
        handler.setSendFailureChannel(producerErrorChannel());
        handler.setSync(false);  // Async for high throughput - errors handled in producerErrorHandlingFlow
        return handler;
    }

    @Bean
    public KafkaTemplate<String, SolaceSyslogEvent> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }

    @Bean
    public ProducerFactory<String, SolaceSyslogEvent> producerFactory() {
        // *** MODIFIED: Store reference for reset capability ***
        this.producerFactory = new DefaultKafkaProducerFactory<>(producerConfigs());
        return this.producerFactory;
    }

    @Bean
    public Map<String, Object> producerConfigs() {
        Map<String, Object> props = new HashMap<>();

        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaConfig.getBrokers());
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, org.apache.kafka.common.serialization.StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);

        props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG,
                kafkaConfig.getRequestTimeoutMs() != null ? kafkaConfig.getRequestTimeoutMs() : 30_000);
        props.put(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG,
                kafkaConfig.getDeliveryTimeoutMs() != null ? kafkaConfig.getDeliveryTimeoutMs() : 120_000);
        props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG,
                kafkaConfig.getMaxBlockMs() != null ? kafkaConfig.getMaxBlockMs() : 60_000);

        props.put(ProducerConfig.RETRIES_CONFIG,
                kafkaConfig.getMaxRetries() != null ? kafkaConfig.getMaxRetries() : Integer.MAX_VALUE);
        props.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG,
                kafkaConfig.getRetryBackoffMs() != null ? kafkaConfig.getRetryBackoffMs() : 1_000);

        props.put(ProducerConfig.LINGER_MS_CONFIG,
                kafkaConfig.getLingerMs() != null ? kafkaConfig.getLingerMs() : 100);
        props.put(ProducerConfig.BATCH_SIZE_CONFIG,
                kafkaConfig.getBatchSize() != null ? kafkaConfig.getBatchSize() : 32 * 1024);
        props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG,
                StringUtils.hasText(kafkaConfig.getCompressionType()) ? kafkaConfig.getCompressionType() : "snappy");
        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG,
                kafkaConfig.getBufferMemory() != null ? kafkaConfig.getBufferMemory() : 64L * 1024 * 1024);

        props.put(ProducerConfig.ACKS_CONFIG,
                StringUtils.hasText(kafkaConfig.getAcks()) ? kafkaConfig.getAcks() : "all");
        props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION,
                kafkaConfig.getMaxInFlightRequests() != null ? kafkaConfig.getMaxInFlightRequests() : 1);
        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);

        if (Boolean.TRUE.equals(kafkaConfig.getSslEnabled())) {
            props.put("security.protocol", kafkaConfig.getSecurityProtocol());
            props.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, kafkaConfig.getSslTruststoreLocation());
            props.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, kafkaConfig.getSslTruststorePassword());
        }

        return props;
    }
}
