package com.scb.fsp.solace;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Profile;
import org.springframework.integration.annotation.IntegrationComponentScan;
import org.springframework.integration.config.EnableIntegration;
import org.springframework.integration.dsl.IntegrationFlow;
import org.springframework.integration.handler.LoggingHandler;
import org.springframework.integration.handler.advice.RequestHandlerRetryAdvice;
import org.springframework.integration.kafka.outbound.KafkaProducerMessageHandler;
import org.springframework.integration.support.MessageBuilder;
import org.springframework.messaging.Message;
import org.springframework.messaging.MessageChannel;
import org.springframework.messaging.support.GenericMessage;
import org.springframework.retry.RetryContext;
import org.springframework.retry.backoff.ExponentialBackOffPolicy;
import org.springframework.retry.policy.SimpleRetryPolicy;
import org.springframework.retry.support.RetryTemplate;
import org.springframework.util.StringUtils;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.expression.common.LiteralExpression;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;
import org.springframework.kafka.support.serializer.JsonSerializer;

import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.TimeoutException;

import static org.apache.kafka.clients.producer.ProducerConfig.ACKS_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.BATCH_SIZE_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.BOOTSTRAP_SERVERS_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.BUFFER_MEMORY_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.COMPRESSION_TYPE_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.LINGER_MS_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.MAX_BLOCK_MS_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION;
import static org.apache.kafka.clients.producer.ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.RETRIES_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.RETRY_BACKOFF_MAX_MS_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.RETRY_BACKOFF_MS_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG;

/**
 * Producer reset on TimeoutException
 */
@Slf4j
@Configuration
@EnableIntegration
@IntegrationComponentScan
@RequiredArgsConstructor
@Profile("kafka")
public class OutboundFlowKafkaConfig {

    private static final String APP_NAME = "solace-otel-collector";

    private final KafkaConfig kafkaConfig;

    // Hold reference for reset capability
    private DefaultKafkaProducerFactory<String, SolaceSyslogEvent> producerFactory;

    /**
     * Main outbound flow:
     * producerChannel -> kafkaMessageHandler (with retry advice)
     */
    @Bean
    public IntegrationFlow kafkaIntegrationFlow(
            @Qualifier("producerChannel") MessageChannel producerChannel,
            KafkaProducerMessageHandler<String, SolaceSyslogEvent> kafkaMessageHandler,
            RequestHandlerRetryAdvice kafkaRetryAdvice
    ) {
        return IntegrationFlow.from(producerChannel)
                .handle(kafkaMessageHandler,
                        e ->
                                e.advice(kafkaRetryAdvice))
                .get();
    }

    @Bean
    public IntegrationFlow producerErrorHandlingFlow(
            @Qualifier("producerErrorChannel") MessageChannel errorChannel
    ) {
        return IntegrationFlow.from(errorChannel)
                .log(LoggingHandler.Level.ERROR, "KafkaErrorLogger", m -> {
                    Object payload = m.getPayload();
                    Throwable cause = null;

                    if (payload instanceof Throwable) {
                        cause = (Throwable) payload;
                    } else if (m.getHeaders().containsKey("exception")) {
                        Object ex = m.getHeaders().get("exception");
                        if (ex instanceof Throwable) {
                            cause = (Throwable) ex;
                        }
                    }

                    return String.format(
                            "Error sending data to Kafka. Headers: %s, Root cause: %s",
                            m.getHeaders(),
                            (cause != null && cause.getMessage() != null)
                                    ? cause.getMessage()
                                    : (cause != null ? cause.toString() : "Unknown")
                    );
                })
                .get();
    }

    @Bean
    public MessageChannel producerErrorChannel() {
        return org.springframework.integration.dsl.MessageChannels
                .queue("producerErrorChannel", 1000)
                .getObject();
    }

    /**
     * Spring Integration retry on the handler itself.
     * Added producer reset in recovery callback
     */
    @Bean
    public RequestHandlerRetryAdvice kafkaRetryAdvice(
            @Qualifier("producerChannel") MessageChannel producerChannel
    ) {
        RequestHandlerRetryAdvice advice = new RequestHandlerRetryAdvice();

        RetryTemplate template = getRetryTemplate();
        advice.setRetryTemplate(template);

        // Reset producer after exhausting retries
        advice.setRecoveryCallback(ctx -> {
            Throwable lastError = ctx.getLastThrowable();

            // Reset producer if it's a timeout/connection error
            if (shouldResetProducer(lastError)) {
                resetProducer();
            }

            Message<?> failed = (Message<?>) ctx.getAttribute("message");
            if (failed != null) {
                producerChannel.send(failed);
            }

            return null;
        });

        return advice;
    }

    private RetryTemplate getRetryTemplate() {
        RetryTemplate template = new RetryTemplate();

        int maxAttempts = kafkaConfig.getMaxRetries() != null ? kafkaConfig.getMaxRetries() : 7;

        SimpleRetryPolicy retryPolicy = new SimpleRetryPolicy(maxAttempts);
        ExponentialBackOffPolicy backOffPolicy = new ExponentialBackOffPolicy();
        backOffPolicy.setInitialInterval(
                kafkaConfig.getRetryBackoffMs() != null ? kafkaConfig.getRetryBackoffMs() : 3_000
        );
        backOffPolicy.setMultiplier(2.0);
        backOffPolicy.setMaxInterval(
                kafkaConfig.getMaxIntervalMs() != null ? kafkaConfig.getMaxIntervalMs() : 180_000
        );

        template.setRetryPolicy(retryPolicy);
        template.setBackOffPolicy(backOffPolicy);
        return template;
    }

    // Check if error warrants producer reset
    private boolean shouldResetProducer(Throwable throwable) {
        if (throwable == null) return false;

        Throwable cause = throwable;
        while (cause != null) {
            String name = cause.getClass().getSimpleName();
            if (cause instanceof TimeoutException
                    || name.contains("NetworkException")
                    || name.contains("DisconnectException")
                    || name.contains("TimeoutException")) {
                return true;
            }
            cause = cause.getCause();
        }

        return false;
    }

    // Reset the producer to force new connection
    private synchronized void resetProducer() {
        if (producerFactory != null) {
            log.warn("Resetting Kafka producer due to connection/timeout error");
            try {
                producerFactory.reset();
                log.warn("Kafka producer reset successfully - new connection will be established");
            } catch (Exception e) {
                log.error("Failed to reset Kafka producer", e);
            }
        }
    }

    /**
     * Kafka handler - synchronous for SI retry to work
     */
    @Bean
    public KafkaProducerMessageHandler<String, SolaceSyslogEvent> kafkaMessageHandler() {
        KafkaProducerMessageHandler<String, SolaceSyslogEvent> handler =
                new KafkaProducerMessageHandler<>(kafkaTemplate());

        handler.setTopicExpression(new LiteralExpression(kafkaConfig.getTopic()));
        handler.setMessageKeyExpression(new LiteralExpression(APP_NAME));
        handler.setSendFailureChannel(producerErrorChannel());
        handler.setSync(Boolean.TRUE.equals(kafkaConfig.getSyncMode()));
        handler.setSendTimeout(kafkaConfig.getSendTimeout() != null ? kafkaConfig.getSendTimeout() : 30_000);
        // ensures producer thread won't block forever

        return handler;
    }

    @Bean
    public KafkaTemplate<String, SolaceSyslogEvent> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }

    @Bean
    public ProducerFactory<String, SolaceSyslogEvent> producerFactory() {
        // Store reference for reset capability
        this.producerFactory = new DefaultKafkaProducerFactory<>(producerConfigs());
        return this.producerFactory;
    }

    @Bean
    public Map<String, Object> producerConfigs() {
        Map<String, Object> props = new HashMap<>();

        // base
        props.put(BOOTSTRAP_SERVERS_CONFIG, kafkaConfig.getBrokers());
        props.put(KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);

        // critical timeouts
        props.put(REQUEST_TIMEOUT_MS_CONFIG,
                kafkaConfig.getRequestTimeoutMs() != null ? kafkaConfig.getRequestTimeoutMs() : 30_000);
        props.put(DELIVERY_TIMEOUT_MS_CONFIG,
                kafkaConfig.getDeliveryTimeoutMs() != null ? kafkaConfig.getDeliveryTimeoutMs() : 120_000);
        props.put(MAX_BLOCK_MS_CONFIG,
                kafkaConfig.getMaxBlockMs() != null ? kafkaConfig.getMaxBlockMs() : 60_000);

        // retries
        props.put(RETRIES_CONFIG,
                kafkaConfig.getMaxRetries() != null ? kafkaConfig.getMaxRetries() : Integer.MAX_VALUE);
        props.put(RETRY_BACKOFF_MS_CONFIG,
                kafkaConfig.getRetryBackoffMs() != null ? kafkaConfig.getRetryBackoffMs() : 1_000);
        props.put(RETRY_BACKOFF_MAX_MS_CONFIG,
                kafkaConfig.getRetryBackoffMaxMs() != null ? kafkaConfig.getRetryBackoffMaxMs() : 5_000);

        // performance
        props.put(LINGER_MS_CONFIG,
                kafkaConfig.getLingerMs() != null ? kafkaConfig.getLingerMs() : 100); // 100 ms linger time
        props.put(BATCH_SIZE_CONFIG,
                kafkaConfig.getBatchSize() != null ? kafkaConfig.getBatchSize() : 32 * 1024); // 32 KB
        props.put(COMPRESSION_TYPE_CONFIG,
                StringUtils.hasText(kafkaConfig.getCompressionType()) ? kafkaConfig.getCompressionType() : "none");
        props.put(BUFFER_MEMORY_CONFIG,
                kafkaConfig.getBufferMemory() != null ? kafkaConfig.getBufferMemory() : (64L * 1024 * 1024)); // 64MB

        // reliability
        props.put(ACKS_CONFIG,
                StringUtils.hasText(kafkaConfig.getAcks()) ? kafkaConfig.getAcks() : "1"); // Ack once leader receives
        props.put(MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION,
                kafkaConfig.getMaxInFlightRequests() != null ? kafkaConfig.getMaxInFlightRequests() : 1);
        // props.put(ENABLE_IDEMPOTENCE_CONFIG, true); // acks should be 'all' for this to be effective

        // security
        props.putAll(kafkaConfig.sslConfig());

        return props;
    }
}
